entry!('kulkarni2016hierarchical',
  title('Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation'),
  author('T. D. Kulkarni and K. Narasimhan and A. Saeedi and J. Tenenbaum'),
  article('Advances in neural information processing systems', 2016),
  pages(3675, 3683),
)

entry!('brafman2002r',
  title('{R}-max-a general polynomial time algorithm for near-optimal reinforcement learning'),
  author('R. Brafman and M. Tennenholtz'),
  article('Journal of Machine Learning Research', 2002),
  pages(213, 231),
    )

entry!('strehl2005theoretical',
  title('A theoretical analysis of model-based interval estimation'),
  author('A. L. Strehl and M. L. Littman'),
  article('Proceedings of the 22nd international conference on Machine learning', 2005),
  pages(856, 863),
  organization('ACM'),
    )

entry!('strehl2009reinforcement',
  title('Reinforcement learning in finite MDPs: {PAC} analysis'),
  author('A. L. Strehl and L. Li and M. L. Littman'),
  article('Journal of Machine Learning Research', 2009),
  pages(2413, 2444),
    )

entry!('osband2013more',
  title('(More) efficient reinforcement learning via posterior sampling'),
  author('I. Osband and D. Russo and B. Van Roy'),
  article('Advances in Neural Information Processing Systems', 2013),
  pages(3003, 3011),
    )

entry!('osband2016posterior',
  title('Why is posterior sampling better than optimism for reinforcement learning'),
  author('I. Osband and B. Van Roy'),
  arxiv(2016, '1607.00215'),
    )

entry!('jaksch2010near',
  title('Near-optimal regret bounds for reinforcement learning'),
  author('T. Jaksch and R. Ortner and P. Auer'),
  article('Journal of Machine Learning Research', 2010),
  pages(1563, 1600),
)

entry!('dann2017unifying',
  title('Unifying {PAC} and regret: Uniform {PAC} bounds for episodic reinforcement learning'),
  author('C. Dann and T. Lattimore and E. Brunskill'),
  article('Advances in Neural Information Processing Systems', 2017),
  pages(5713, 5723),
)

entry!('azar2017minimax',
  title('Minimax regret bounds for reinforcement learning'),
  author('M. G. Azar and I. Osband and R. Munos'),
  icml(2017),
)

entry!('singh1995reinforcement',
  title('Reinforcement learning with soft state aggregation'),
  author('S. P. Singh and T. Jaakkola and M. Jordan'),
  article('Advances in neural information processing systems', 1995),
  pages(361, 368),
)

entry!('dietterich2000hierarchical',
  title('Hierarchical reinforcement learning with the {MAXQ} value function decomposition'),
  author('T. G. Dietterich'),
  article('Journal of Artificial Intelligence Research', 2000),
  pages(227, 303),
)

entry!('aytar2018playing',
  title('Playing hard exploration games by watching YouTube'),
  author('Y. Aytar and T. Pfaff and D Budden and T. L. Paine and Z. Wang and N. de Freitas'),
  arxiv(2018, '1805.11592'),
)

entry!('pohlen2018observe',
  title('Observe and Look Further: Achieving Consistent Performance on {ATARI}'),
  author('T. Pohlen and B. Piot and T. Hester and M. G. Azar and D. Horgan and D. Budden and G. Barth-Maron  and H. van Hasselt and J. Quan and M. Ve{\v{c}}er{\'\i}k and others'),
  arxiv(2018, '1805.11593'),
)
entry!('sutton1995td',
  title('{TD} models: Modeling the world at a mixture of time scales'),
  author('R. S. Sutton'),
  article('Machine Learning Proceedings', 1995),
  pages(531, 539),
  publisher('Elsevier'),
)

entry!('vezhnevets2017feudal',
  title('Feudal networks for hierarchical reinforcement learning'),
  author('A. S. Vezhnevets and S. Osindero and T. Schaul and N. Heess and M. Jaderberg and D. Silver and K. Kavukcuoglu'),
  arxiv(2017, '1703.01161'),
)

entry!('kirkpatrick2017overcoming',
  title('Overcoming catastrophic forgetting in neural networks'),
  author('J. Kirkpatrick and R. Pascanu and N. Rabinowitz and J. Veness and G. Desjardins and A. A. Rusu and K. Milan and J. Quan and T. Ramalho and A. Grabska-Barwinska and others'),
  article('Proceedings of the national academy of sciences', 2017),
  publisher('National Acad Sciences'),
)

entry!('keramati2018strategic',
   title('Strategic Object Oriented Reinforcement Learning'),
   author('R. Keramati and J. Whang and P. Cho and E. Brunskill'),
   arxiv(2018, '1806.00175'),
 )

entry!('oh2018self',
  title('Self-Imitation Learning'),
  author('J. Oh and Y. Guo and S. Singh and H. Lee'),
  arxiv(2018, ':1806.05635'),
)

entry!('dann2018polynomial',
  title('On Polynomial Time {PAC} Reinforcement Learning with Rich Observations'),
  author('C. Dann and N. Jiang and A. Krishnamurthy and A. Agarwal and J. Langford and R. E. Schapire'),
  arxiv(2018, '1803.00606'),
)

entry!('jiang2016contextual',
  title('Contextual decision processes with low Bellman rank are {PAC}-learnable'),
  author('N. Jiang and A. Krishnamurthy and A. Agarwal and J. Langford and R. E. Schapire'),
  arxiv(2016, '1610.09512'),
)

entry!('russo2013eluder',
  title('Eluder dimension and the sample complexity of optimistic exploration'),
  author('D. Russo and B. Van Roy'),
  article('Advances in Neural Information Processing Systems', 2013),
  pages(2256, 2264),
)

entry!('wen2013efficient',
  title('Efficient exploration and value function generalization in deterministic systems'),
  author('Z. Wen and B. Van Roy'),
  article('Advances in Neural Information Processing Systems', 2013),
  pages(3021, 3029),
)

entry!('islam2017reproducibility',
  title('Reproducibility of benchmarked deep reinforcement learning tasks for continuous control'),
  author('R. Islam and P. Henderson and M. Gomrokchi and D. Precup'),
  arxiv(2017, '1708.04133'),
)

entry!('machado2017revisiting',
  title('Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents'),
  author('M. C. Machado and M. G. Bellemare and E. Talvitie and J. Veness and M. Hausknecht and M. Bowling'),
  arxiv(2017, '1709.06009'),
)
