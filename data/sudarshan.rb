entry!('kulkarni2016hierarchical',
  title('Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation'),
  author('Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh'),
  article('Advances in neural information processing systems', 2016),
  pages(3675, 3683),
)

entry!('brafman2002r',
  title('{R}-max-a general polynomial time algorithm for near-optimal reinforcement learning'),
  author('Brafman, Ronen I and Tennenholtz, Moshe'),
  article('Journal of Machine Learning Research', 2002),
  pages(213, 231),
    )

entry!('strehl2005theoretical',
  title('A theoretical analysis of model-based interval estimation'),
  author('Strehl, Alexander L and Littman, Michael L'),
  article('Proceedings of the 22nd international conference on Machine learning', 2005),
  pages(856, 863),
  organization('ACM'),
    )

entry!('strehl2009reinforcement',
  title('Reinforcement learning in finite MDPs: {PAC} analysis'),
  author('Strehl, Alexander L and Li, Lihong and Littman, Michael L'),
  article('Journal of Machine Learning Research', 2009),
  pages(2413, 2444),
    )

entry!('osband2013more',
  title('(More) efficient reinforcement learning via posterior sampling'),
  author('Osband, Ian and Russo, Daniel and Van Roy, Benjamin'),
  article('Advances in Neural Information Processing Systems', 2013),
  pages(3003, 3011),
    )

entry!('osband2016posterior',
  title('Why is posterior sampling better than optimism for reinforcement learning'),
  author('Osband, Ian and Van Roy, Benjamin'),
  arxiv(2016, '1607.00215'),
    )

entry!('jaksch2010near',
  title('Near-optimal regret bounds for reinforcement learning'),
  author('Jaksch, Thomas and Ortner, Ronald and Auer, Peter'),
  article('Journal of Machine Learning Research', 2010),
  pages(1563, 1600),
)

entry!('dann2017unifying',
  title('Unifying {PAC} and regret: Uniform {PAC} bounds for episodic reinforcement learning'),
  author('Dann, Christoph and Lattimore, Tor and Brunskill, Emma'),
  article('Advances in Neural Information Processing Systems', 2017),
  pages(5713, 5723),
)

entry!('azar2017minimax',
  title('Minimax regret bounds for reinforcement learning'),
  author('Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi}'),
  icml(2017),
)

entry!('singh1995reinforcement',
  title('Reinforcement learning with soft state aggregation'),
  author('Singh, Satinder P and Jaakkola, Tommi and Jordan, Michael I'),
  article('Advances in neural information processing systems', 1995),
  pages(361, 368),
)

entry!('dietterich2000hierarchical',
  title('Hierarchical reinforcement learning with the {MAXQ} value function decomposition'),
  author('Dietterich, Thomas G'),
  article('Journal of Artificial Intelligence Research', 2000),
  pages(227, 303),
)

entry!('aytar2018playing',
  title('Playing hard exploration games by watching YouTube'),
  author('Aytar, Yusuf and Pfaff, Tobias and Budden, David and Paine, Tom Le and Wang, Ziyu and de Freitas, Nando'),
  arxiv(2018, '1805.11592'),
)

entry!('pohlen2018observe',
  title('Observe and Look Further: Achieving Consistent Performance on {ATARI}'),
  author('Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others'),
  arxiv(2018, '1805.11593'),
)
entry!('sutton1995td',
  title('{TD} models: Modeling the world at a mixture of time scales'),
  author('Sutton, Richard S'),
  article('Machine Learning Proceedings', 1995),
  pages(531, 539),
  publisher('Elsevier'),
)

entry!('vezhnevets2017feudal',
  title('Feudal networks for hierarchical reinforcement learning'),
  author('Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray'),
  arxiv(2017, '1703.01161'),
)

